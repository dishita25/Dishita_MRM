{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"CarPrice_Assignment.csv\")\n",
    "y = X['price']\n",
    "y = y.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "X.drop(['car_ID','price'], axis=1, inplace=True)\n",
    "X[\"doornumber\"] = X[\"doornumber\"].replace(\"four\",4).replace(\"two\",2)\n",
    "X[\"cylindernumber\"] = X[\"cylindernumber\"].replace({\"four\": 4, \"five\": 5, \"six\": 6, \"three\": 3, \"twelve\": 12, \"two\": 2, \"eight\": 8})\n",
    "\n",
    "X = pd.get_dummies(X, columns=['CarName','fueltype','aspiration','carbody','drivewheel','enginelocation','enginetype','fuelsystem'])\n",
    "X = X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the features\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "y = (y - y.mean(axis=0)) / y.std(axis=0)\n",
    "\n",
    "X = np.hstack((X ,np.ones((X.shape[0],1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, weights, alpha, iterations):\n",
    "    m = len(X)\n",
    "    cost_history = np.zeros(iterations)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        predictions = np.dot(X, weights)\n",
    "        error = predictions - y\n",
    "        gradient = (1/m) * np.dot(X.T, error)\n",
    "        weights -= alpha * gradient\n",
    "        cost_history[i] = (1/(2*m)) * np.dot(error.T, error)\n",
    "        if np.isnan(cost_history[i]):\n",
    "            print(f\"NaN encountered at iteration {i}\")\n",
    "            break\n",
    "    \n",
    "    return weights, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, y, alpha, iterations):\n",
    "    weights = np.zeros((X.shape[1], 1))\n",
    "    weights, cost_history = gradient_descent(X, y, weights, alpha, iterations)\n",
    "    \n",
    "    return weights, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "ratio = 0.8\n",
    "\n",
    "rows = X.shape[0]\n",
    "train_size = int(ratio*rows)\n",
    "\n",
    "X_train = X[0:train_size]\n",
    "X_test = X[train_size:]\n",
    "\n",
    "y_train = y[0:train_size]\n",
    "y_test = y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dishita\\AppData\\Local\\Temp\\ipykernel_20316\\677469361.py:10: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cost_history[i] = (1/(2*m)) * np.dot(error.T, error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized theta parameters: [[ 7.50561536e-02]\n",
      " [ 6.55936813e-02]\n",
      " [-3.21805886e-02]\n",
      " [-1.89919072e-01]\n",
      " [ 1.38840776e-01]\n",
      " [-4.22853921e-02]\n",
      " [ 8.02923119e-01]\n",
      " [ 2.31785715e-02]\n",
      " [ 3.07927552e-01]\n",
      " [-9.56187797e-02]\n",
      " [-7.88338859e-02]\n",
      " [-6.57149056e-02]\n",
      " [ 9.16978927e-03]\n",
      " [ 2.45692259e-01]\n",
      " [ 3.01003405e-01]\n",
      " [-1.28851495e-01]\n",
      " [ 1.55065876e-03]\n",
      " [ 1.94191360e-04]\n",
      " [-4.29138437e-02]\n",
      " [-1.65781356e-02]\n",
      " [ 3.26933452e-02]\n",
      " [ 9.00981162e-03]\n",
      " [ 2.53610839e-02]\n",
      " [ 2.27126538e-02]\n",
      " [ 3.65604641e-03]\n",
      " [ 2.60660665e-02]\n",
      " [ 1.99435975e-02]\n",
      " [ 5.76735817e-02]\n",
      " [ 6.98829014e-02]\n",
      " [ 3.70583308e-02]\n",
      " [ 1.20842165e-01]\n",
      " [ 4.40751156e-02]\n",
      " [-2.22052055e-02]\n",
      " [ 8.67742503e-03]\n",
      " [ 7.15017682e-02]\n",
      " [-1.10378115e-02]\n",
      " [ 3.88864356e-02]\n",
      " [ 8.70884385e-02]\n",
      " [ 2.26040617e-02]\n",
      " [ 1.53558642e-02]\n",
      " [ 3.94642845e-02]\n",
      " [-1.61652621e-02]\n",
      " [-2.94130737e-02]\n",
      " [-4.01825049e-03]\n",
      " [-2.48922638e-02]\n",
      " [-3.29288176e-02]\n",
      " [-1.16203423e-02]\n",
      " [-9.36721549e-03]\n",
      " [ 1.90069412e-04]\n",
      " [ 9.93652597e-03]\n",
      " [-2.45658386e-02]\n",
      " [-2.64202236e-02]\n",
      " [ 1.95095475e-02]\n",
      " [-4.89298300e-03]\n",
      " [-3.02127446e-03]\n",
      " [ 1.27558473e-02]\n",
      " [-1.06559263e-02]\n",
      " [ 1.42419608e-02]\n",
      " [ 1.27232828e-02]\n",
      " [-1.93030030e-03]\n",
      " [ 6.35538712e-04]\n",
      " [-4.58912265e-03]\n",
      " [-1.20103726e-02]\n",
      " [-4.54214978e-02]\n",
      " [-1.38299538e-02]\n",
      " [-4.27510309e-02]\n",
      " [-4.13618105e-02]\n",
      " [ 1.18979890e-02]\n",
      " [-8.45534185e-04]\n",
      " [ 2.41339120e-02]\n",
      " [ 3.38894453e-02]\n",
      " [ 2.36728610e-02]\n",
      " [ 2.22349725e-02]\n",
      " [-1.17377142e-02]\n",
      " [ 1.21701987e-02]\n",
      " [ 3.47606181e-03]\n",
      " [ 5.06903219e-02]\n",
      " [ 1.74943191e-02]\n",
      " [-1.91618731e-02]\n",
      " [-1.43432237e-02]\n",
      " [-2.09439931e-02]\n",
      " [-4.05137896e-02]\n",
      " [-1.80162037e-02]\n",
      " [-3.46972529e-02]\n",
      " [-4.04873116e-02]\n",
      " [-2.84880477e-02]\n",
      " [-4.26838059e-02]\n",
      " [-2.47101304e-02]\n",
      " [-1.54051600e-02]\n",
      " [ 2.49447992e-04]\n",
      " [ 1.56634173e-02]\n",
      " [-4.52261660e-02]\n",
      " [-4.58932247e-05]\n",
      " [ 1.06490890e-02]\n",
      " [ 2.11104679e-02]\n",
      " [-5.64623352e-03]\n",
      " [-2.03293100e-02]\n",
      " [ 3.72721078e-03]\n",
      " [-5.32441398e-02]\n",
      " [ 1.68138459e-02]\n",
      " [-4.62920549e-02]\n",
      " [-4.83024972e-02]\n",
      " [-1.97399238e-02]\n",
      " [-7.53949864e-03]\n",
      " [-3.38147769e-02]\n",
      " [-7.21918839e-04]\n",
      " [-5.79734309e-02]\n",
      " [-3.97833910e-02]\n",
      " [-3.91626265e-02]\n",
      " [-2.19350669e-02]\n",
      " [ 1.01831002e-02]\n",
      " [-1.16847745e-02]\n",
      " [ 6.05721773e-02]\n",
      " [ 2.07683669e-03]\n",
      " [ 9.40017095e-03]\n",
      " [ 1.77740658e-02]\n",
      " [ 1.67678427e-02]\n",
      " [ 2.20469761e-02]\n",
      " [ 3.71253315e-02]\n",
      " [-1.19344340e-04]\n",
      " [-2.48389181e-02]\n",
      " [ 2.52733507e-03]\n",
      " [ 7.68329896e-03]\n",
      " [ 2.91466435e-02]\n",
      " [-4.17896603e-03]\n",
      " [ 1.13042722e-02]\n",
      " [-1.21375636e-03]\n",
      " [ 1.50143374e-02]\n",
      " [-5.30854496e-02]\n",
      " [-3.33592019e-03]\n",
      " [-3.33592019e-03]\n",
      " [ 3.67600503e-02]\n",
      " [ 7.21736847e-03]\n",
      " [ 2.75070404e-02]\n",
      " [-4.63521945e-02]\n",
      " [-3.33592019e-03]\n",
      " [ 4.02387119e-04]\n",
      " [ 6.85022211e-03]\n",
      " [-3.33592019e-03]\n",
      " [-6.45054875e-03]\n",
      " [-3.33592019e-03]\n",
      " [ 1.14335106e-02]\n",
      " [-4.72930926e-03]\n",
      " [-3.33592019e-03]\n",
      " [-3.33592019e-03]\n",
      " [-3.33592019e-03]\n",
      " [-3.33592019e-03]\n",
      " [-3.33592019e-03]\n",
      " [-4.72930926e-03]\n",
      " [-3.33592019e-03]\n",
      " [-3.33592019e-03]\n",
      " [-3.33592019e-03]\n",
      " [-3.33592019e-03]\n",
      " [-3.33592019e-03]\n",
      " [-4.72930926e-03]\n",
      " [-4.72930926e-03]\n",
      " [-4.72930926e-03]\n",
      " [-3.33592019e-03]\n",
      " [-3.33592019e-03]\n",
      " [-4.72930926e-03]\n",
      " [-3.33592019e-03]\n",
      " [-3.33592019e-03]\n",
      " [-3.33592019e-03]\n",
      " [ 1.47657170e-02]\n",
      " [-1.47657170e-02]\n",
      " [-2.30253907e-02]\n",
      " [ 2.30253907e-02]\n",
      " [ 4.03599441e-03]\n",
      " [ 1.09041774e-01]\n",
      " [-3.62131665e-02]\n",
      " [ 3.38767814e-02]\n",
      " [-6.57904094e-02]\n",
      " [-7.07235230e-02]\n",
      " [-1.21791038e-01]\n",
      " [ 1.54225690e-01]\n",
      " [-3.25439551e-02]\n",
      " [ 3.25439551e-02]\n",
      " [ 6.37667087e-02]\n",
      " [-4.27350459e-03]\n",
      " [-5.89624067e-02]\n",
      " [ 3.42457245e-02]\n",
      " [ 2.94427899e-02]\n",
      " [-8.67626078e-02]\n",
      " [-1.94927827e-02]\n",
      " [-6.23945368e-02]\n",
      " [ 7.83675485e-02]\n",
      " [-3.61875710e-02]\n",
      " [ 1.47657170e-02]\n",
      " [-9.36721549e-03]\n",
      " [-3.28641166e-02]\n",
      " [-1.08218312e-02]\n",
      " [-4.80188568e-02]\n",
      " [ 4.77631084e-02]]\n",
      "Final cost: 0.001188663\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1648\n",
    "iterations = 10000\n",
    "\n",
    "weights, cost_history = linear_regression(X_train, y_train, alpha, iterations)\n",
    "\n",
    "print(\"Optimized theta parameters:\", weights)\n",
    "print(\"Final cost:\", round(cost_history[-1],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.35370177260539265\n",
      "MAE: 0.4513611829714883\n",
      "R-squared: -0.24836735595429582\n"
     ]
    }
   ],
   "source": [
    "def accuracy(X_test, y_test, weights):\n",
    "    y_pred = np.dot(X_test, weights)\n",
    "    \n",
    "    mse = np.mean((y_test - y_pred) ** 2)\n",
    "    \n",
    "    mae = np.mean(np.abs(y_test - y_pred))\n",
    "    \n",
    "    ss_total = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "    ss_res = np.sum((y_test - y_pred) ** 2)\n",
    "    r_squared = 1 - (ss_res / ss_total)\n",
    "    \n",
    "    return mse, mae, r_squared\n",
    "\n",
    "mse, mae, r_squared = accuracy(X_test, y_test, weights)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R-squared:\", r_squared)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
